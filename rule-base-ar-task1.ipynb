{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gc\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sess = pd.read_csv('sessions_train.csv')\n",
    "df_prod = pd.read_csv('products_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prev_items', 'next_item', 'locale'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_sess['locale'].unique()\n",
    "df_sess.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verf√ºgbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 St√ºck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413511</th>\n",
       "      <td>B08D7KW8VK</td>\n",
       "      <td>UK</td>\n",
       "      <td>TOMHOUSEE Anime Cosplay Short Straight Hair Wi...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>TOMHOUSEE</td>\n",
       "      <td>Deep Grey Yuki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Synthetic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413512</th>\n",
       "      <td>B073WXLXR9</td>\n",
       "      <td>UK</td>\n",
       "      <td>Crystals NEW brilliant ink twister bingo dabbe...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>CRYSTALS</td>\n",
       "      <td>Orange,blue,green,pink,red,purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413513</th>\n",
       "      <td>1529393833</td>\n",
       "      <td>UK</td>\n",
       "      <td>Before I Do: the new, funny and unexpected lov...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>Hodder Paperbacks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cousens, Sophie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413514</th>\n",
       "      <td>B0B3TJ1NDN</td>\n",
       "      <td>UK</td>\n",
       "      <td>Black iPhone Charger Cable, iPhone Charger Bra...</td>\n",
       "      <td>4.49</td>\n",
       "      <td>AA-TECH</td>\n",
       "      <td>Black</td>\n",
       "      <td>2M</td>\n",
       "      <td>brd-ip-black-2022</td>\n",
       "      <td>Nylon Braided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Added Protection: An additional layer of prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413515</th>\n",
       "      <td>B00HUBEG3Y</td>\n",
       "      <td>UK</td>\n",
       "      <td>Kids B Crafty 100 Mini Pegs, Mini Wooden Pegs,...</td>\n",
       "      <td>3.99</td>\n",
       "      <td>Kids B Crafty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üîµ Mini Pegs : 100 Wooden Pegs For Decoration, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1413516 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id locale                                              title  \\\n",
       "0        B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1        B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2        B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3        B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4        B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "...             ...    ...                                                ...   \n",
       "1413511  B08D7KW8VK     UK  TOMHOUSEE Anime Cosplay Short Straight Hair Wi...   \n",
       "1413512  B073WXLXR9     UK  Crystals NEW brilliant ink twister bingo dabbe...   \n",
       "1413513  1529393833     UK  Before I Do: the new, funny and unexpected lov...   \n",
       "1413514  B0B3TJ1NDN     UK  Black iPhone Charger Cable, iPhone Charger Bra...   \n",
       "1413515  B00HUBEG3Y     UK  Kids B Crafty 100 Mini Pegs, Mini Wooden Pegs,...   \n",
       "\n",
       "         price              brand                              color  \\\n",
       "0        30.95         RED DRAGON                                NaN   \n",
       "1        17.90        Simply Keto                                NaN   \n",
       "2        68.89         Sennheiser                       Multi-Colour   \n",
       "3        18.99       Amy & Benton                         Animal Car   \n",
       "4         7.17          PLAYMOBIL                  Nicht Zutreffend.   \n",
       "...        ...                ...                                ...   \n",
       "1413511   9.99          TOMHOUSEE                     Deep Grey Yuki   \n",
       "1413512   8.99           CRYSTALS  Orange,blue,green,pink,red,purple   \n",
       "1413513   4.50  Hodder Paperbacks                                NaN   \n",
       "1413514   4.49            AA-TECH                              Black   \n",
       "1413515   3.99      Kids B Crafty                                NaN   \n",
       "\n",
       "                     size              model            material  \\\n",
       "0                     NaN            RDD0089                 NaN   \n",
       "1        750 g (1er Pack)                NaN                 NaN   \n",
       "2                One size             508377          Kunstleder   \n",
       "3                     NaN              2008B  aufziehauto 1 jahr   \n",
       "4                 OneSize              70522        Polypropylen   \n",
       "...                   ...                ...                 ...   \n",
       "1413511               NaN                NaN           Synthetic   \n",
       "1413512               NaN                NaN             Plastic   \n",
       "1413513               NaN                NaN                 NaN   \n",
       "1413514                2M  brd-ip-black-2022       Nylon Braided   \n",
       "1413515               NaN                NaN         Alloy Steel   \n",
       "\n",
       "                  author                                               desc  \n",
       "0                    NaN  Amberjacks Steel Dartpfeile sind verf√ºgbar in ...  \n",
       "1                    NaN  üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2                    NaN  3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...  \n",
       "3                    NaN  „ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...  \n",
       "4                    NaN                                    Inhalt: 1 St√ºck  \n",
       "...                  ...                                                ...  \n",
       "1413511              NaN                                                NaN  \n",
       "1413512              NaN                                                NaN  \n",
       "1413513  Cousens, Sophie                                                NaN  \n",
       "1413514              NaN  Added Protection: An additional layer of prote...  \n",
       "1413515              NaN  üîµ Mini Pegs : 100 Wooden Pegs For Decoration, ...  \n",
       "\n",
       "[1413516 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod_task1 = df_prod[df_prod['locale'].isin(['UK', 'DE', 'JP'])]\n",
    "df_prod_task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_items</th>\n",
       "      <th>next_item</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['B09W9FND7K' 'B09JSPLN1M']</td>\n",
       "      <td>B09M7GY217</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...</td>\n",
       "      <td>B001B4THSA</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...</td>\n",
       "      <td>B0767DTG2Q</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...</td>\n",
       "      <td>B0B4R9NN4B</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']</td>\n",
       "      <td>B0BGVBKWGZ</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272711</th>\n",
       "      <td>['B06XK89969' 'B01NGT5NF4' 'B00D5Z89C8' 'B07ZV...</td>\n",
       "      <td>B07VL2W1DR</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272712</th>\n",
       "      <td>['B076M85W1K' 'B07L8792Q9' 'B095RW318L' 'B095R...</td>\n",
       "      <td>B095RQ2LCY</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272713</th>\n",
       "      <td>['B00JQDIQRQ' 'B001O59QQE']</td>\n",
       "      <td>B088M5YT6Y</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272714</th>\n",
       "      <td>['B07QMHMLJZ' 'B07FPYYMC4']</td>\n",
       "      <td>B07PFF814D</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272715</th>\n",
       "      <td>['B06XC9TW57' 'B08WYQ4S11']</td>\n",
       "      <td>B08WZ4CSRQ</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3272716 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prev_items   next_item locale\n",
       "0                              ['B09W9FND7K' 'B09JSPLN1M']  B09M7GY217     DE\n",
       "1        ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...  B001B4THSA     DE\n",
       "2        ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...  B0767DTG2Q     DE\n",
       "3        ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...  B0B4R9NN4B     DE\n",
       "4                 ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']  B0BGVBKWGZ     DE\n",
       "...                                                    ...         ...    ...\n",
       "3272711  ['B06XK89969' 'B01NGT5NF4' 'B00D5Z89C8' 'B07ZV...  B07VL2W1DR     UK\n",
       "3272712  ['B076M85W1K' 'B07L8792Q9' 'B095RW318L' 'B095R...  B095RQ2LCY     UK\n",
       "3272713                        ['B00JQDIQRQ' 'B001O59QQE']  B088M5YT6Y     UK\n",
       "3272714                        ['B07QMHMLJZ' 'B07FPYYMC4']  B07PFF814D     UK\n",
       "3272715                        ['B06XC9TW57' 'B08WYQ4S11']  B08WZ4CSRQ     UK\n",
       "\n",
       "[3272716 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sess_task1 = df_sess[df_sess['locale'].isin(['UK', 'DE', 'JP'])]\n",
    "df_sess_task1\n",
    "# these can be decreased to smaller datasets to try faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('sessions_test_task1.csv')\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2list(x):\n",
    "    x = x.replace('[', '').replace(']', '').replace(\"'\", '').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    l = [i for i in x.split() if i]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log10\n",
    "import collections as col\n",
    "\n",
    "class AssociationRules: \n",
    "    '''\n",
    "    SequentialRules(steps = 3, weighting='div', pruning=0.0)\n",
    "        \n",
    "    Parameters\n",
    "    --------\n",
    "    steps : int\n",
    "        TODO. (Default value: 3)\n",
    "    weighting : string\n",
    "        TODO. (Default value: 3)\n",
    "    pruning : float\n",
    "        TODO. (Default value: 20)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__( self, pruning=20, session_key='SessionId', item_key='ItemId' ):\n",
    "        self.pruning = pruning\n",
    "        self.session_key = session_key\n",
    "        self.item_key = item_key\n",
    "        self.session = -1\n",
    "        self.session_items = []\n",
    "            \n",
    "    def fit( self, data, test=None ):\n",
    "        '''\n",
    "        Trains the predictor.\n",
    "        \n",
    "        Parameters\n",
    "        --------\n",
    "        data: pandas.DataFrame\n",
    "            Training data. It contains the transactions of the sessions. It has one column for session IDs, one for item IDs and one for the timestamp of the events (unix timestamps).\n",
    "            It must have a header. Column names are arbitrary, but must correspond to the ones you set during the initialization of the network (session_key, item_key, time_key properties).\n",
    "        \n",
    "            \n",
    "        '''\n",
    "\n",
    "        cur_session = -1\n",
    "        last_items = []\n",
    "        rules = dict()\n",
    "        \n",
    "        index_session = data.columns.get_loc( self.session_key )\n",
    "        index_item = data.columns.get_loc( self.item_key )\n",
    "        \n",
    "        for row in data.itertuples( index=False ):\n",
    "            \n",
    "            session_id, item_id = row[index_session], row[index_item]\n",
    "            \n",
    "            if session_id != cur_session:\n",
    "                cur_session = session_id\n",
    "                last_items = []\n",
    "            else: \n",
    "                for item_id2 in last_items: \n",
    "                    \n",
    "                    if not item_id in rules :\n",
    "                        rules[item_id] = dict()\n",
    "                    \n",
    "                    if not item_id2 in rules :\n",
    "                        rules[item_id2] = dict()\n",
    "                    \n",
    "                    if not item_id in rules[item_id2]:\n",
    "                        rules[item_id2][item_id] = 0\n",
    "                    \n",
    "                    if not item_id2 in rules[item_id]:\n",
    "                        rules[item_id][item_id2] = 0\n",
    "                    \n",
    "                    rules[item_id][item_id2] += 1\n",
    "                    rules[item_id2][item_id] += 1\n",
    "                    \n",
    "            last_items.append( item_id )\n",
    "        \n",
    "        if self.pruning > 0 :\n",
    "            self.prune( rules )\n",
    "            \n",
    "        self.rules = rules\n",
    "    \n",
    "    def linear(self, i):\n",
    "        return 1 - (0.1*i) if i <= 10 else 0\n",
    "    \n",
    "    def same(self, i):\n",
    "        return 1\n",
    "    \n",
    "    def div(self, i):\n",
    "        return 1/i\n",
    "    \n",
    "    def log(self, i):\n",
    "        return 1/(log10(i+1.7))\n",
    "    \n",
    "    def quadratic(self, i):\n",
    "        return 1/(i*i)\n",
    "    \n",
    "    def predict_next(self, session_id, input_item_id, predict_for_item_ids, skip=False, mode_type='view', timestamp=0):\n",
    "        '''\n",
    "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
    "                \n",
    "        Parameters\n",
    "        --------\n",
    "        session_id : int or string\n",
    "            The session IDs of the event.\n",
    "        input_item_id : int or string\n",
    "            The item ID of the event.\n",
    "        predict_for_item_ids : 1D array\n",
    "            IDs of items for which the network should give prediction scores. Every ID must be in the set of item IDs of the training set.\n",
    "            \n",
    "        Returns\n",
    "        --------\n",
    "        out : pandas.Series\n",
    "            Prediction scores for selected items on how likely to be the next item of this session. Indexed by the item IDs.\n",
    "        \n",
    "        '''\n",
    "        if session_id != self.session:\n",
    "            self.session_items = []\n",
    "            self.session = session_id\n",
    "        \n",
    "        if mode_type == 'view':\n",
    "            self.session_items.append( input_item_id )\n",
    "            \n",
    "        if skip:\n",
    "            return\n",
    "        \n",
    "        preds = np.zeros( len(predict_for_item_ids) ) \n",
    "             \n",
    "        if input_item_id in self.rules:\n",
    "            for key in self.rules[input_item_id]:\n",
    "                preds[ predict_for_item_ids == key ] = self.rules[input_item_id][key]\n",
    "        \n",
    "        series = pd.Series(data=preds, index=predict_for_item_ids)\n",
    "        \n",
    "        series = series / series.max()\n",
    "        \n",
    "        return series \n",
    "    \n",
    "    def prune(self, rules): \n",
    "        '''\n",
    "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
    "        Parameters\n",
    "            --------\n",
    "            rules : dict of dicts\n",
    "                The rules mined from the training data\n",
    "        '''\n",
    "        for k1 in rules:\n",
    "            tmp = rules[k1]\n",
    "            if self.pruning < 1:\n",
    "                keep = len(tmp) - int( len(tmp) * self.pruning )\n",
    "            elif self.pruning >= 1:\n",
    "                keep = self.pruning\n",
    "            counter = col.Counter( tmp )\n",
    "            rules[k1] = dict()\n",
    "            for k2, v in counter.most_common( keep ):\n",
    "                rules[k1][k2] = v              \n",
    "                \n",
    "    def clear(self):\n",
    "        self.rules = {}\n",
    "\n",
    "    def support_users(self):\n",
    "        '''\n",
    "          whether it is a session-based or session-aware algorithm\n",
    "          (if returns True, method \"predict_with_training_data\" must be defined as well)\n",
    "\n",
    "          Parameters\n",
    "          --------\n",
    "\n",
    "          Returns\n",
    "          --------\n",
    "          True : if it is session-aware\n",
    "          False : if it is session-based\n",
    "        '''\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              ['B09W9FND7K' 'B09JSPLN1M']\n",
       "1        ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...\n",
       "2        ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...\n",
       "3        ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...\n",
       "4                 ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']\n",
       "                               ...                        \n",
       "49995                          ['B09SNZWHSK' 'B071GFD83G']\n",
       "49996    ['B0B8BZK7XP' 'B0B8BQWNBJ' 'B0B81ZWGRM' 'B0B81...\n",
       "49997    ['B09XXRVK57' 'B09XXT9W7Q' 'B0B253MDJ1' 'B0B24...\n",
       "49998    ['B09JRJ3NYV' '3747203949' 'B09JRLJX7G' 'B08LJ...\n",
       "49999    ['3741524794' '3473315788' '3473316466' '34734...\n",
       "Name: prev_items, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "train_data = df_sess_task1['prev_items'][:50000]\n",
    "test_data = df_sess_task1['prev_items'][50000:100000]\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SessionId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SessionId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# # Fit an AR model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# model = AutoReg(train_data,lags=4)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# ar_model = model.fit()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39m# # Evaluate the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# predictions = ar_model.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m ar \u001b[39m=\u001b[39m AssociationRules()\n\u001b[0;32m----> 8\u001b[0m ar\u001b[39m.\u001b[39;49mfit(data\u001b[39m=\u001b[39;49mdf_sess_task1)\n",
      "Cell \u001b[0;32mIn[70], line 45\u001b[0m, in \u001b[0;36mAssociationRules.fit\u001b[0;34m(self, data, test)\u001b[0m\n\u001b[1;32m     42\u001b[0m last_items \u001b[39m=\u001b[39m []\n\u001b[1;32m     43\u001b[0m rules \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m---> 45\u001b[0m index_session \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc( \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession_key )\n\u001b[1;32m     46\u001b[0m index_item \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_key )\n\u001b[1;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitertuples( index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SessionId'"
     ]
    }
   ],
   "source": [
    "# # Fit an AR model\n",
    "# model = AutoReg(train_data,lags=4)\n",
    "# ar_model = model.fit()\n",
    "\n",
    "# # Evaluate the model\n",
    "# predictions = ar_model.predict(start=len(train_data), end=len(train_data)+len(test_data)-1)\n",
    "ar = AssociationRules()\n",
    "ar.fit(data=df_sess_task1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_item_dict = defaultdict(list)\n",
    "\n",
    "for _, row in tqdm(df_sess.iterrows(), total=len(df_sess)):\n",
    "    prev_items = str2list(row['prev_items'])\n",
    "    next_item = row['next_item']\n",
    "    prev_items_length = len(prev_items)\n",
    "    if prev_items_length <= 1:\n",
    "        next_item_dict[prev_items[0]].append(next_item)\n",
    "    else:\n",
    "        for i, item in enumerate(prev_items[:-1]):\n",
    "            next_item_dict[item].append(prev_items[i+1])\n",
    "        next_item_dict[prev_items[-1]].append(next_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    prev_items = str2list(row['prev_items'])\n",
    "    prev_items_length = len(prev_items)\n",
    "    if prev_items_length <= 1:\n",
    "        continue\n",
    "    else:\n",
    "        for i, item in enumerate(prev_items[:-1]):\n",
    "            next_item_dict[item].append(prev_items[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_item_map = {}\n",
    "\n",
    "for item in tqdm(next_item_dict):\n",
    "    counter = Counter(next_item_dict[item])\n",
    "    next_item_map[item] = [i[0] for i in counter.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "v = []\n",
    "\n",
    "for item in next_item_dict:\n",
    "    k.append(item)\n",
    "    v.append(next_item_dict[item])\n",
    "    \n",
    "df_next = pd.DataFrame({'item': k, 'next_item': v})\n",
    "df_next = df_next.explode('next_item').reset_index(drop=True)\n",
    "df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top200 = df_next['next_item'].value_counts().index.tolist()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test['last_item'] = df_test['prev_items'].apply(lambda x: str2list(x)[-1])\n",
    "df_test['next_item_prediction'] = df_test['last_item'].map(next_item_map)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    pred_orig = row['next_item_prediction']\n",
    "    pred = pred_orig\n",
    "    prev_items = str2list(row['prev_items'])\n",
    "    if type(pred) == float:\n",
    "        pred = top200[:100]\n",
    "    else:\n",
    "        if len(pred_orig) < 100:\n",
    "            for i in top200:\n",
    "                if i not in pred_orig and i not in prev_items:\n",
    "                    pred.append(i)\n",
    "                if len(pred) >= 100:\n",
    "                    break\n",
    "        else:\n",
    "            pred = pred[:100]\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['next_item_prediction'] = preds\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['next_item_prediction'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[['locale', 'next_item_prediction']].to_parquet('submission_task1.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_sess[\"next_item\"])\n",
    "# print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
